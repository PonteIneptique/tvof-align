{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "Download all data from https://figshare.com/articles/The_Histoire_ancienne_jusqu_C_sar_A_Digital_Edition_The_Values_of_French_/11907081\n",
    "\n",
    "There should be in the same folder as this file:\n",
    "\n",
    "- `2_TVOF_lemmatised_contexts_1.0.xml`\n",
    "- `3_TVOF_Fr20125_tokenised_1.0.xml`\n",
    "- `4_TVOF_Royal20D1_tokenised_1.0xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(\"2_TVOF_lemmatised_contexts_1.0.xml\") as f:\n",
    "    KWIC = ET.parse(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick explanations\n",
    "\n",
    "1. I tried first to go full xpath (`//*[@xml:id='#location']//w[@n='#n']`) but this was very slow (~ 10h).\n",
    "2. `lxml.etree` provides a parseId that returns a tuple (ElementTree, IDDict) where the IDDict returns a nice dictionary containing all `@xml:id`s.\n",
    "3. The best way from there was to check for all w inside. But div could have both seg, and head. Note sure I did not collide with anything else (small checks are in place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13756/13756 [00:00<00:00, 14725.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# In the original file, xml:id=\"edfr20125_genNotes\" is duplicated. The second was updated as \"edfr20125_genNotes2\"\n",
    "Global_Dict = defaultdict(dict)\n",
    "with open(\"3_TVOF_Fr20125_tokenised_1.0.xml\") as f:\n",
    "    FR20125, FR20125_Dict = ET.parseid(f)\n",
    "    for location_id in tqdm.tqdm(FR20125_Dict):\n",
    "        location = FR20125_Dict[location_id]\n",
    "        if location.tag == \"{http://www.tei-c.org/ns/1.0}div\" and location.attrib[\"type\"] != \"note\":\n",
    "            for w in location.xpath(\n",
    "                \"./tei:head//tei:w[@n]\",\n",
    "                namespaces={\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "            ):\n",
    "                if w.attrib[\"n\"] in Global_Dict[location_id]:\n",
    "                    print(f\"{w.attrib['n']} already in {location_id}\")\n",
    "                Global_Dict[location_id][w.attrib[\"n\"]] = w\n",
    "        elif location.tag == \"{http://www.tei-c.org/ns/1.0}div\" and location.attrib[\"type\"] == \"note\":\n",
    "            continue # Ignore note\n",
    "        else:\n",
    "            for w in location.xpath(\n",
    "                \".//tei:w[@n]\",\n",
    "                namespaces={\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "            ):\n",
    "                if w.attrib[\"n\"] in Global_Dict[location_id]:\n",
    "                    print(f\"{w.attrib['n']} already in {location_id}\")\n",
    "                Global_Dict[location_id][w.attrib[\"n\"]] = w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15613/15613 [00:00<00:00, 24248.21it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"4_TVOF_Royal20D1_tokenised_1.0.xml\") as f:\n",
    "    edRoyal, edRoyal_Dict = ET.parseid(f)\n",
    "    for location_id in tqdm.tqdm(edRoyal_Dict):\n",
    "        location = edRoyal_Dict[location_id]\n",
    "        if location.tag == \"{http://www.tei-c.org/ns/1.0}div\" and location.attrib[\"type\"] != \"note\":\n",
    "            for w in location.xpath(\n",
    "                \".//tei:head//tei:w[@n]\",\n",
    "                namespaces={\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "            ):\n",
    "                Global_Dict[location_id][w.attrib[\"n\"]] = w\n",
    "        else:\n",
    "            for w in location.xpath(\n",
    "                \".//tei:w[@n]\",\n",
    "                namespaces={\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "            ):\n",
    "                Global_Dict[location_id][w.attrib[\"n\"]] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_Dict  = edRoyal_BetterDict + FR20125_BetterDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 249664/364893 [00:00<00:00, 276054.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FR] ERROR ON FR20125 : <item type=\"seg_item\" location=\"edfr20125_00651_08\" n=\"96\" preceding=\"pluisors et meismement ausi des autors en lor\" following=\". Tant nori Faustus et sa feme\" lemma=\"livre2\" lemmaPos=\"s.m.\" sp=\"\">\n",
      "      <string>livres</string><punctuation type=\"end\">.</punctuation>\n",
      "    </item>\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364893/364893 [00:01<00:00, 271386.06it/s]\n"
     ]
    }
   ],
   "source": [
    "xpath = len(KWIC.xpath(\"//item\"))\n",
    "\n",
    "for data in tqdm.tqdm(KWIC.xpath(\"//item\")):\n",
    "    location = data.attrib[\"location\"]\n",
    "    n = data.attrib[\"n\"]\n",
    "    \n",
    "    try:\n",
    "        w = Global_Dict[location][n]\n",
    "        w.attrib[\"lemma\"] = data.attrib.get(\"lemma\", \"\")\n",
    "        w.attrib[\"pos\"] = data.attrib.get(\"lemmaPos\", data.attrib.get(\"pos\", \"\"))\n",
    "        w.attrib[\"ana\"] = data.attrib.get(\"sp\", \"\")\n",
    "    except KeyError:\n",
    "        print(f\"[FR] ERROR ON {title} : {ET.tostring(data, encoding=str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3_TVOF_Fr20125_tokenised_1.0_collated.xml\", \"w\") as f:\n",
    "    f.write(ET.tostring(FR20125, encoding=str))\n",
    "with open(\"4_TVOF_Royal20D1_tokenised_1.0_collated.xml\", \"w\") as f:\n",
    "    f.write(ET.tostring(edRoyal, encoding=str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
